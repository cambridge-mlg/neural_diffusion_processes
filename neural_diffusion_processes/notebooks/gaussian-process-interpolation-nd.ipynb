{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb29db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from functools import partial\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import diffrax as dfx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "\n",
    "from check_shapes import check_shapes\n",
    "\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "import neural_diffusion_processes as ndp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ededcbc",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "JITTER = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d4b59d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_2d_grid(num, min_=-1, max_=1):\n",
    "    x = jnp.linspace(min_, max_, num)\n",
    "    x1, x2 = jnp.meshgrid(x, x)\n",
    "    x = jnp.stack([x1.flatten(), x2.flatten()], axis=-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11baa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from jaxtyping import Array\n",
    "\n",
    "\n",
    "class MultiOutputKernel:\n",
    "    def __init__(self, kernel, output_dim: int):\n",
    "        self.kernel = kernel\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    @check_shapes(\n",
    "        \"x: [input_dim]\",\n",
    "        \"y: [input_dim]\",\n",
    "        \"return: [output_dim, output_dim]\",\n",
    "    )\n",
    "    def __call__(self, x, y):\n",
    "        ...\n",
    "\n",
    "\n",
    "class DiagMultiOutputKernel(MultiOutputKernel):\n",
    "\n",
    "    @check_shapes(\n",
    "        \"x: [input_dim]\",\n",
    "        \"y: [input_dim]\",\n",
    "        \"return: [output_dim, output_dim]\",\n",
    "    )\n",
    "    def __call__(self, x, y):\n",
    "        return self.kernel(x, y) * jnp.eye(self.output_dim)\n",
    "\n",
    "\n",
    "\n",
    "output_dim = 2\n",
    "beta_schedule = ndp.sde.LinearBetaSchedule()\n",
    "x = get_2d_grid(25)\n",
    "k0 = ndp.kernels.SquaredExpontialKernel(lengthscale=0.25)\n",
    "k0 = DiagMultiOutputKernel(k0, output_dim=output_dim)\n",
    "k0 = ndp.kernels.RBFDivFree(lengthscale=.25)\n",
    "\n",
    "k1 = ndp.kernels.WhiteKernel()\n",
    "k1 = DiagMultiOutputKernel(k1, output_dim=output_dim)\n",
    "\n",
    "\n",
    "class MultiOutputMeanFunction:\n",
    "    def __init__(self, output_dim: int):\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    @check_shapes(\n",
    "        \"x: [input_dim]\",\n",
    "        \"return: [output_dim]\"\n",
    "    )\n",
    "    def __call__(self, x):\n",
    "        ...\n",
    "    \n",
    "class ZeroMultiOutputMeanFunction(MultiOutputMeanFunction):\n",
    "\n",
    "    @check_shapes(\n",
    "        \"x: [input_dim]\",\n",
    "        \"return: [output_dim]\"\n",
    "    )\n",
    "    def __call__(self, x):\n",
    "        return jnp.zeros((self.output_dim,))\n",
    "    \n",
    "    \n",
    "mean_function = ZeroMultiOutputMeanFunction(output_dim)\n",
    "\n",
    "@check_shapes(\"x: [N, input_dim]\", \"return: [N, output_dim]\")\n",
    "def eval_meanfunction(mf: MultiOutputMeanFunction, x):\n",
    "    return jax.vmap(lambda x_: mf.__call__(x_))(x)\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "@check_shapes(\n",
    "    \"x: [n1, input_dim]\",\n",
    "    \"y: [n2, input_dim] if (y is not None)\",\n",
    "    \"return: [n1, n2, output_dim, output_dim] if (y is not None)\",\n",
    "    \"return: [n1, n1, output_dim, output_dim] if (y is None)\" ,\n",
    ")\n",
    "def gram(kernel, x: Array, y: Optional[Array] = None) -> Array:\n",
    "    y = x if (y is None) else y\n",
    "\n",
    "    @partial(jax.vmap, in_axes=[0, None])\n",
    "    @partial(jax.vmap, in_axes=[None, 0])\n",
    "    def G(x_, y_):\n",
    "        return kernel(x_, y_)\n",
    "    \n",
    "    return G(x, y)\n",
    "    \n",
    "\n",
    "kxx = gram(k0, x)\n",
    "kxx = rearrange(kxx, 'n1 n2 p1 p2 -> (p1 n1) (p2 n2)') \n",
    "plt.matshow(kxx)\n",
    "\n",
    "print(eval_meanfunction(mean_function, x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1638fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.tree_util as jtu\n",
    "from neural_diffusion_processes.types import PyTree\n",
    "\n",
    "class MatVecControlTerm(dfx.ControlTerm):\n",
    "\n",
    "    @staticmethod\n",
    "    def prod(vf: PyTree, control: PyTree) -> PyTree:\n",
    "        return jtu.tree_map(lambda a,b: a @ b, vf, control)\n",
    "\n",
    "\n",
    "@check_shapes(\"t: []\", \"yt: [NP, 1]\", \"x: [N, D]\", \"return: [NP, 1]\",)\n",
    "def drift(t, yt, x):\n",
    "    mu = eval_meanfunction(mean_function, x)  # [N, P]\n",
    "    mu = rearrange(mu, \"n p -> (n p) 1\")\n",
    "    return  - 0.5 * beta_schedule(t) * (yt - mu)\n",
    "    \n",
    "@check_shapes(\"t: []\", \"yt: [NP, 1]\", \"x: [N, D]\", \"return: [NP, NP]\",)\n",
    "def diffusion(t, yt, x):\n",
    "    del yt\n",
    "    kxx = gram(k1, x, x)  # [N, N, P, P]\n",
    "    kxx = rearrange(kxx, 'n1 n2 p1 p2 -> (n1 p1) (n2 p2)')\n",
    "    sqrt_k = jnp.linalg.cholesky(kxx + JITTER * jnp.eye(len(kxx)))\n",
    "    return jnp.sqrt(beta_schedule(t)) * sqrt_k\n",
    "\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "@check_shapes(\"y0: [N, P]\", \"return[0]: [T]\", \"return[1]: [T, N, P]\")\n",
    "def solve(key, y0) -> Tuple[Array, Array]:\n",
    "    n, p = y0.shape[0], y0.shape[1]\n",
    "    y0 = rearrange(y0, 'n p -> (n p) 1')\n",
    "    shape = jax.ShapeDtypeStruct(y0.shape, y0.dtype)\n",
    "    bm = dfx.VirtualBrownianTree(t0=beta_schedule.t0, t1=beta_schedule.t1, tol=1e-3 / 2., shape=shape, key=key)\n",
    "    terms = dfx.MultiTerm(dfx.ODETerm(drift), MatVecControlTerm(diffusion, bm))\n",
    "    t0, t1 = beta_schedule.t0, beta_schedule.t1\n",
    "    # logarithmic timesteps to have more steps at small timesteps... \n",
    "    ts = t0 + (t1 - t0) * (jnp.exp(jnp.linspace(t0, t1, 9)) - jnp.exp(t0)) / (jnp.exp(t1) - jnp.exp(t0))\n",
    "    ts = jnp.linspace(t0, t1, 9)\n",
    "    saveat = dfx.SaveAt(ts=ts)\n",
    "    sol = dfx.diffeqsolve(terms, solver=dfx.Euler(), t0=t0, t1=t1, dt0=1e-3, y0=y0, args=x, saveat=saveat, adjoint=dfx.NoAdjoint())\n",
    "    return (\n",
    "        sol.ts, rearrange(sol.ys, \"t (n p) 1 -> t n p\", p=p, t=len(ts))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb2740a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "@check_shapes(\n",
    "    \"x: [N, D]\",\n",
    "    \"return: [S, N, P] if num_samples\",\n",
    "    \"return: [N, P] if not num_samples\"\n",
    ")\n",
    "def sample_gp(key, kernel: MultiOutputKernel, mean_function: MultiOutputMeanFunction, x, num_samples: int | None = 10):\n",
    "    kxx = gram(kernel, x, x)  # [N, N, P, P]\n",
    "    kxx = rearrange(kxx, 'n1 n2 p1 p2 -> (n1 p1) (n2 p2)')\n",
    "    mu = eval_meanfunction(mean_function, x)  # [N, P]\n",
    "    p = mu.shape[-1]\n",
    "    mu = rearrange(mu, \"n p -> (n p) 1\")\n",
    "    samples = ndp.misc.sample_mvn(key, mu, kxx, num_samples)\n",
    "    if num_samples is not None:\n",
    "        return rearrange(samples, \"s (n p) 1 -> s n p\", p=p)\n",
    "    else:\n",
    "        return rearrange(samples, \"(n p) 1 -> n p\", p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c033d1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "key = jax.random.PRNGKey(seed)\n",
    "\n",
    "# Solves forward SDE for multiple initia states using vmap.\n",
    "num_samples = 2\n",
    "key, subkey = jax.random.split(key)\n",
    "y0s= sample_gp(subkey, k0, mean_function, x, num_samples=num_samples)\n",
    "print(y0s.shape)\n",
    "subkeys = jax.random.split(key, num=num_samples)\n",
    "out = jax.vmap(solve, in_axes=[0, 0])(subkeys, y0s)\n",
    "print(out[0].shape)\n",
    "print(out[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e343bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "norm = matplotlib.colors.Normalize()\n",
    "cm = sns.cubehelix_palette(start=0.5, rot=-0.75, as_cmap=True, reverse=True)\n",
    "\n",
    "ts, ys = out\n",
    "plot_num_timesteps = ys.shape[1]\n",
    "fig, axes = plt.subplots(\n",
    "    plot_num_timesteps, num_samples, sharex=True, sharey=True, figsize=(8, 16)\n",
    ")\n",
    "for j in range(plot_num_timesteps):\n",
    "    for i in range(num_samples):\n",
    "        if x.shape[-1] == 1:\n",
    "            for o in range(output_dim):\n",
    "                axes[j, i].plot(x, ys[i, j, :, o], '-', ms=2)\n",
    "        elif x.shape[-1] == 2:\n",
    "            y_norm = jnp.linalg.norm(ys[i, j], axis=-1)\n",
    "            axes[j, i].quiver(\n",
    "                x[:, 0],\n",
    "                x[:, 1],\n",
    "                ys[i, j, :, 0],\n",
    "                ys[i, j, :, 1],\n",
    "                color=cm(norm(y_norm)),\n",
    "                scale=50,\n",
    "                width=0.005,\n",
    "            )  \n",
    "\n",
    "        axes[j, 0].set_ylabel(f\"t = {ts[0, j]:.2f}\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edcf3e4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "@check_shapes(\n",
    "    \"t: []\",\n",
    "    \"x: [N, D]\",\n",
    "    \"y0: [N, P] if y0 is not None\",\n",
    "    \"return[0]: [N, P]\",\n",
    "    \"return[1]: [N, N, P, P]\",\n",
    ")\n",
    "def pt(x, t, y0=None):\n",
    "    \"\"\"Marginal of OU process at time t. When passing y0 this returns the conditional marginal.\"\"\"\n",
    "    # TODO: change if limiting processes have different mean functions.\n",
    "    mean0 = mean1 = mean_function\n",
    "    mean_coef = jnp.exp(-0.5 * beta_schedule.B(t))\n",
    "\n",
    "    mean1 = eval_meanfunction(mean1, x)  # [N, P]\n",
    "\n",
    "    if y0 is None:\n",
    "        mean0 = eval_meanfunction(mean0, x)  # [N, P]\n",
    "        mean = mean_coef * mean0 + (1.0 - mean_coef) * mean1\n",
    "    else:\n",
    "        mean = mean_coef * y0 + (1.0 - mean_coef) * mean1\n",
    "    \n",
    "    k1xx = gram(k1, x)\n",
    "\n",
    "    if y0 is None:\n",
    "        k0xx = gram(k0, x)\n",
    "        cov = k1xx + jnp.exp(-beta_schedule.B(t)) * (k0xx - k1xx)\n",
    "    else:\n",
    "        cov = (1.0 -  jnp.exp(-beta_schedule.B(t))) * k1xx\n",
    "    \n",
    "    return mean, cov\n",
    "\n",
    "\n",
    "@check_shapes(\n",
    "    \"t: []\",\n",
    "    \"x: [N, D]\",\n",
    "    \"y0: [N, P] if y0 is not None\",\n",
    "    \"return: [N, P]\",\n",
    ")\n",
    "def sample_pt(key, x, t, y0=None):\n",
    "    \"Marginal distribution p(yt) if y0 is passed p(yt | xt)\"\n",
    "    mean, cov = pt(x, t, y0)\n",
    "    n, p = mean.shape[0], mean.shape[1]\n",
    "    mean = rearrange(mean, \"n p -> (n p) 1\", n=n, p=p)\n",
    "    cov = rearrange(cov, 'n1 n2 p1 p2 -> (n1 p1) (n2 p2)', n1=n, n2=n, p1=p, p2=p)\n",
    "    s = ndp.misc.sample_mvn(key, mean, cov)  # [np, 1]\n",
    "    return rearrange(s, '(n p) 1 -> n p', n=n, p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58760a05",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "if x.shape[-1] == 1:\n",
    "    fig, axes = plt.subplots(plot_num_timesteps, num_samples, sharex=True, sharey=True, figsize=(8, 7))\n",
    "\n",
    "    for t_index in range(plot_num_timesteps):\n",
    "        for sample_index in range(num_samples):\n",
    "            t = ts[0, t_index]\n",
    "            mean, cov = pt(x, t, ys[sample_index, 0])\n",
    "            for o in range(output_dim):\n",
    "                covd = cov[..., o, o]\n",
    "                std = jnp.diag(covd).reshape(-1,1)**0.5\n",
    "                axes[t_index, sample_index].plot(x, ys[sample_index, t_index, :, o], 'o-', ms=2)\n",
    "                axes[t_index, sample_index].plot(x, mean[..., o:o+1], 'k--', alpha=.5)\n",
    "                lo, up = (v.flatten() for v in (mean[..., o:o+1] - 2 * std, mean[..., o:o+1] + 2 * std))\n",
    "                axes[t_index, sample_index].fill_between(x.flatten(), lo, up, alpha=.1, color='k')\n",
    "            axes[t_index, 0].set_ylabel(f\"t = {t:.2f}\")\n",
    "            axes[t_index, sample_index].set_ylim(-2.5, 2.5)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae38620b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "solve_lower_triangular = partial(jax.scipy.linalg.solve_triangular, lower=True)  # L⁻¹ x\n",
    "solve_upper_triangular = partial(jax.scipy.linalg.solve_triangular, lower=False)  # U⁻¹ x\n",
    "\n",
    "from check_shapes import check_shape as cs\n",
    "\n",
    "\n",
    "@check_shapes(\"yt: [NP, 1]\", \"x: [N, D]\", \"t: []\", \"return: [NP, 1]\",)\n",
    "def preconditioned_score(yt, x, t):\n",
    "    \"Exact marginal score in Gaussian setting\"\n",
    "    mu_t, Sigma_t = pt(x, t)\n",
    "    n, p = mu_t.shape[0], mu_t.shape[1]\n",
    "    mu_t = rearrange(mu_t, \"n p -> (n p) 1\", n=n, p=p)\n",
    "    Sigma_t = rearrange(Sigma_t, 'n1 n2 p1 p2 -> (n1 p1) (n2 p2)', n1=n, n2=n, p1=p, p2=p)\n",
    "    Lt = jnp.linalg.cholesky(Sigma_t + JITTER * jnp.eye(len(Sigma_t)))\n",
    "    b = yt - mu_t\n",
    "    A = solve_upper_triangular(jnp.transpose(Lt), solve_lower_triangular(Lt, b))\n",
    "    k1xx = cs(gram(k1, x), \"[N, N, P, P]\")\n",
    "    k1xx = rearrange(k1xx, 'n1 n2 p1 p2 -> (n1 p1) (n2 p2)', n1=n, n2=n, p1=p, p2=p)\n",
    "    return cs(- k1xx @ A, \"[NP, 1]\")\n",
    "\n",
    "\n",
    "@check_shapes(\"t: []\", \"yt: [NP, 1]\", \"x: [N, D]\", \"return: [NP, 1]\",)\n",
    "def reverse_drift_ode(t, yt, x):\n",
    "    return  drift(t, yt, x) - 0.5 * beta_schedule(t) * preconditioned_score(yt, x, t) # [N, 1]\n",
    "\n",
    "# def reverse_drift_sde(t, yt, x):\n",
    "#     return  drift(t, yt, x) - beta_schedule(t) * preconditioned_score(yt, x, t) # [N, 1]\n",
    "\n",
    "@check_shapes(\"yT: [N, P]\", \"return[0]: [T]\", \"return[1]: [T, N, P]\")\n",
    "def reverse_solve(key, yT, prob_flow: bool = True):\n",
    "    n, p = yT.shape[0], yT.shape[1]\n",
    "    yT = rearrange(yT, 'n p -> (n p) 1')\n",
    "    t0, t1 = beta_schedule.t0, beta_schedule.t1\n",
    "    ts = t1 + (t0 - t1) * (jnp.exp(jnp.linspace(t0, t1, 9)) - jnp.exp(t0)) / (jnp.exp(t1) - jnp.exp(t0))\n",
    "    ts = jnp.linspace(t0, t1, 9)[::-1]\n",
    "    saveat = dfx.SaveAt(ts=ts)\n",
    "    # reverse time, solve from t1 to t0\n",
    "    if prob_flow:\n",
    "        terms = dfx.ODETerm(reverse_drift_ode)\n",
    "    else:\n",
    "        pass\n",
    "        # drift = dfx.ODETerm(reverse_drift_sde)\n",
    "        # shape = jax.ShapeDtypeStruct(yT.shape, yT.dtype)\n",
    "        # bm = dfx.VirtualBrownianTree(t0=t1, t1=t0, tol=1e-3 / 2., shape=shape, key=key)\n",
    "        # terms = dfx.MultiTerm(drift, MatVecControlTerm(diffusion, bm))\n",
    "\n",
    "    sol = dfx.diffeqsolve(terms, solver=dfx.Euler(), t0=t1, t1=t0, dt0=-1e-3/2., y0=yT, saveat=saveat, args=x, adjoint=dfx.NoAdjoint())\n",
    "    return (\n",
    "        sol.ts, rearrange(sol.ys, \"t (n p) 1 -> t n p\", t=len(ts), n=n, p=p)\n",
    "    )\n",
    "\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "key, *subkeys = jax.random.split(key, 1+num_samples)\n",
    "rev_out = jax.vmap(reverse_solve)(jnp.stack(subkeys), ys[:, -1])\n",
    "\n",
    "key, *subkeys = jax.random.split(key, 1+num_samples)\n",
    "rev_out2 = jax.vmap(reverse_solve)(jnp.stack(subkeys), ys[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4157b32",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(plot_num_timesteps, num_samples, sharex=True, sharey=True, figsize=(8, 16))\n",
    "for t in range(plot_num_timesteps):\n",
    "    for i in range(num_samples):\n",
    "        if x.shape[-1] == 1:\n",
    "            for o in range(output_dim):\n",
    "                axes[t, i].plot(x, rev_out[1][i, t, :, o], '-', ms=2)\n",
    "                axes[t, i].plot(x, rev_out2[1][i, t, :, o], ':', ms=2)\n",
    "            axes[t, i].set_ylim(-2.5, 2.5)\n",
    "        elif x.shape[-1] == 2 and output_dim == 2:\n",
    "            y_norm = jnp.linalg.norm(rev_out[1][i, t], axis=-1)\n",
    "            axes[t, i].quiver(\n",
    "                x[:, 0],\n",
    "                x[:, 1],\n",
    "                rev_out[1][i, t, :, 0],\n",
    "                rev_out[1][i, t, :, 1],\n",
    "                color=cm(norm(y_norm)),\n",
    "                scale=50,\n",
    "                width=0.005,\n",
    "            )  \n",
    "            axes[t, i].set_ylim(-1, 1)\n",
    "            axes[t, i].set_xlim(-1, 1)\n",
    "\n",
    "        axes[t, 0].set_ylabel(f\"t = {rev_out[0][0, t]:.2f}\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f95588",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@check_shapes(\n",
    "    \"x_context: [num_context, D]\",\n",
    "    \"y_context: [num_context, P]\",\n",
    "    \"x_target: [num_target, D]\",\n",
    "    \"return: [num_target, P]\",\n",
    ")\n",
    "def conditional_sample(key, x_context, y_context, x_target, num_steps: int, num_inner_steps: int):\n",
    "    num_context = len(x_context)\n",
    "    num_target = len(x_target)\n",
    "    p = y_context.shape[1]\n",
    "\n",
    "    # y_context = rearrange(y_context, \"n p -> (n p) 1\", n=num_context, p=p)\n",
    "\n",
    "    shape_augmented_state = [(num_context + num_target) * p, 1]\n",
    "\n",
    "    t0 = beta_schedule.t0\n",
    "    t1 = beta_schedule.t1\n",
    "    ts = jnp.linspace(t1, t0, num_steps, endpoint=True)\n",
    "    dt = ts[0] - ts[1]\n",
    "\n",
    "    solver = dfx.Euler()\n",
    "    # reverse ODE:\n",
    "    ode_terms_reverse = dfx.ODETerm(reverse_drift_ode)\n",
    "\n",
    "    # reverse SDE:\n",
    "    # shape = jax.ShapeDtypeStruct(shape_augmented_state, y_context.dtype)\n",
    "    # key, subkey = jax.random.split(key)\n",
    "    # bm = dfx.VirtualBrownianTree(t0=t1, t1=t0, tol=dt, shape=shape, key=subkey)\n",
    "    # ode_terms_reverse = dfx.MultiTerm(dfx.ODETerm(reverse_drift_sde), dfx.ControlTerm(diffusion, bm))\n",
    "\n",
    "    # forward SDE:\n",
    "    shape = jax.ShapeDtypeStruct(shape_augmented_state, y_context.dtype)\n",
    "    key, subkey = jax.random.split(key)\n",
    "    bm = dfx.VirtualBrownianTree(t0=t0, t1=t1, tol=dt, shape=shape, key=subkey)\n",
    "    sde_terms_forward = dfx.MultiTerm(dfx.ODETerm(drift), MatVecControlTerm(diffusion, bm))\n",
    "\n",
    "    def inner_loop(key, yt, t):\n",
    "        yt_context = sample_pt(key, x_context, t, y_context)\n",
    "        yt_context = rearrange(yt_context, \"n p -> (n p) 1\", n=num_context, p=p)\n",
    "        yt_augmented = jnp.concatenate([yt_context, yt], axis=0)\n",
    "        x_augmented = jnp.concatenate([x_context, x_target], axis=0)\n",
    "\n",
    "        # reverse step\n",
    "        yt_m_dt, *_ = solver.step(ode_terms_reverse, t, t - dt, yt_augmented, x_augmented, None, made_jump=False)\n",
    "\n",
    "        # forward step\n",
    "        yt, *_ = solver.step(sde_terms_forward, t - dt, t, yt_m_dt, x_augmented, None, made_jump=False)\n",
    "\n",
    "        # strip context from augmented state\n",
    "        return yt[num_context * p:], yt_m_dt[num_context * p:]\n",
    "\n",
    "    def outer_loop(key, yt, t):\n",
    "        _, yt_m_dt = jax.lax.scan(lambda yt, key: inner_loop(key, yt, t), yt, jax.random.split(key, num_inner_steps))\n",
    "        yt = yt_m_dt[-1]\n",
    "        return yt, yt\n",
    "\n",
    "\n",
    "    key, subkey = jax.random.split(key)\n",
    "    # yT = sample_pt(subkey, x_test, 1.0)\n",
    "    yT = cs(sample_gp(subkey, k1, mean_function, x_target, num_samples=None), \"[N, P]\")\n",
    "    yT = rearrange(yT, \"n p -> (n p) 1\", n=num_target, p=p)\n",
    "\n",
    "    xs = (ts[:-1], jax.random.split(key, len(ts) - 1))\n",
    "    y0, _ = jax.lax.scan(lambda yt, x: outer_loop(x[1], yt, x[0]), yT, xs)\n",
    "    return rearrange(y0, \"(n p) 1 -> n p\", n=num_target, p=p)\n",
    "\n",
    "\n",
    "if x.shape[-1] == 1:\n",
    "    x_known = jnp.reshape(jnp.asarray([[-0.2, 0.2, 0.6]]), (-1, 1))\n",
    "elif x.shape[-1] == 2:\n",
    "    x_known = jnp.zeros((1, 2)) + 1.e-2\n",
    "\n",
    "if x.shape[-1] == 1 and output_dim == 1:\n",
    "    y_known = jnp.reshape(jnp.asarray([[0.0, -1.0, 0.0]]), (len(x_known), output_dim))\n",
    "elif x.shape[-1] == 1 and output_dim == 2:\n",
    "    y_known = jnp.reshape(jnp.asarray([[0.0, -1.0, 3.0, .2, 1.1, 0.]]), (len(x_known), output_dim))\n",
    "elif x.shape[-1] == 2 and output_dim == 2:\n",
    "    y_known = jnp.reshape(jnp.asarray([[8., 0]]), (1, 2))\n",
    "\n",
    "\n",
    "print(x_known.shape)\n",
    "print(y_known.shape)\n",
    "\n",
    "if x.shape[-1] == 1:\n",
    "    x_test = jnp.linspace(-1, 1, 101)[:, None]\n",
    "elif x.shape[-1] == 2:\n",
    "    x_test = get_2d_grid(21)\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "num_samples = 100 if x.shape[-1] == 1 else 9\n",
    "samples = jax.vmap(lambda key: conditional_sample(key, x_known, y_known, x_test, 100, 1))(jax.random.split(key, num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e018e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "if x.shape[-1] == 1:\n",
    "    plt.figure()\n",
    "    for o in range(output_dim):\n",
    "        plt.plot(x_test, samples[..., o].T, f\"C{o}-\", alpha=.2)\n",
    "        plt.plot(x_known, y_known[:, o], f\"kx\")\n",
    "\n",
    "\n",
    "elif x.shape[-1] == 2 and output_dim == 2:\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(20, 20), sharex=True, sharey=True)\n",
    "\n",
    "    for i, ax in enumerate(np.array(axes).ravel()):\n",
    "        s_norm = jnp.linalg.norm(samples[i], axis=-1)\n",
    "        ax.quiver(\n",
    "            x_test[:, 0],\n",
    "            x_test[:, 1],\n",
    "            samples[i, :, 0],\n",
    "            samples[i, :, 1],\n",
    "            color=cm(norm(s_norm)),\n",
    "            scale=50,\n",
    "            width=0.005,\n",
    "        )  \n",
    "        ax.quiver(\n",
    "            x_known[:, 0],\n",
    "            x_known[:, 1],\n",
    "            y_known[:, 0],\n",
    "            y_known[:, 1],\n",
    "            color='r',\n",
    "            scale=50,\n",
    "            width=0.005,\n",
    "        )  \n",
    "        ax.set_ylim(-1, 1)\n",
    "        ax.set_xlim(-1, 1)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('conditional_divfree.png', dpi=300, facecolor='white', edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7720d110",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
