{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_table_from_metric(\n",
    "    metric,\n",
    "    results,\n",
    "    val_metric=None,\n",
    "    ci=0.95,\n",
    "    latex=False,\n",
    "    bold=True,\n",
    "    drop_nans=False,\n",
    "    show_group=False,\n",
    "    select_best=True,\n",
    "    pm=True\n",
    "):\n",
    "    if val_metric is None:\n",
    "        val_metric = metric\n",
    "\n",
    "    alpha = (1 - ci) / 2\n",
    "\n",
    "    if drop_nans:\n",
    "        results = results[results[metric].notna()]\n",
    "        results = results[results[val_metric].notna()]\n",
    "\n",
    "    def half_ci(group):\n",
    "        data = group.to_numpy()\n",
    "        sem = stats.sem(data)\n",
    "        t2 = stats.t.ppf(1 - alpha, len(data) - 1) - stats.t.ppf(alpha, len(data) - 1)\n",
    "        return sem * (t2 / 2)\n",
    "        # return np.std(data)\n",
    "\n",
    "    def lower_ci(group):\n",
    "        data = group.to_numpy()\n",
    "        sem = stats.sem(data)\n",
    "        mean = data.mean()\n",
    "        t = stats.t.ppf(alpha, len(data) - 1)\n",
    "        return mean + sem * t\n",
    "\n",
    "    def upper_ci(group):\n",
    "        data = group.to_numpy()\n",
    "        sem = stats.sem(data)\n",
    "        mean = data.mean()\n",
    "        t = stats.t.ppf(1 - alpha, len(data) - 1)\n",
    "        return mean + sem * t\n",
    "\n",
    "    def count(group):\n",
    "        data = group.to_numpy()\n",
    "        return np.prod(data.shape)\n",
    "    \n",
    "\n",
    "    results = (\n",
    "        results.groupby(by=[\"group\", \"method\", \"dataset\"])\n",
    "        .agg(\n",
    "            {\n",
    "                metric: [\"mean\", \"std\", \"sem\", lower_ci, upper_ci, half_ci, count],\n",
    "                val_metric: [\n",
    "                    \"mean\",\n",
    "                    \"std\",\n",
    "                    \"sem\",\n",
    "                    lower_ci,\n",
    "                    upper_ci,\n",
    "                    half_ci,\n",
    "                    count,\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    if select_best:\n",
    "        group_max_idx = (\n",
    "            results.groupby(by=[\"method\", \"dataset\"]).transform(max)[val_metric][\"mean\"]\n",
    "            == results[val_metric][\"mean\"]\n",
    "        )\n",
    "        table = results[group_max_idx]\n",
    "    else:\n",
    "        table = results\n",
    "\n",
    "    # table = table[table[\"dataset\"].isin([\"Earthquake\", \"Fire\", \"Flood\", \"Volcano\"])]\n",
    "\n",
    "    if latex:\n",
    "\n",
    "        def format_result(row):\n",
    "            if pm:\n",
    "                return (\n",
    "                    f\"{{{row[metric]['mean']:0.2f}_{{\\pm {row[metric]['half_ci']:0.2f}}}}}\"\n",
    "                )\n",
    "            else:\n",
    "                return f\"{{{row[metric]['mean']:0.2f}}}\"\n",
    "\n",
    "\n",
    "        def bold_result(row):\n",
    "            return \"\\\\bm\" + row[\"result\"] if row[\"bold\"].any() else row[\"result\"]\n",
    "\n",
    "    else:\n",
    "\n",
    "        def format_result(row):\n",
    "            if pm:\n",
    "                return f\"{row[metric]['mean']:0.2f} Â± {row[metric]['half_ci']:0.2f}\"\n",
    "            else:\n",
    "                return f\"{row[metric]['mean']:0.2f}\"\n",
    "\n",
    "        def bold_result(row):\n",
    "            return \"* \" + row[\"result\"] if row[\"bold\"].any() else row[\"result\"]\n",
    "\n",
    "    table[\"group_max\"] = table.groupby(by=[\"dataset\"]).transform(max)[metric][\"mean\"]\n",
    "    table[\"group_max\"] = table.apply(\n",
    "        lambda row: table.index[table[metric][\"mean\"] == row[\"group_max\"].squeeze()][0],\n",
    "        axis=1,\n",
    "    )\n",
    "    table[\"bold\"] = table.apply(\n",
    "        lambda row: (\n",
    "            table.loc[row[\"group_max\"], (metric, \"mean\")].squeeze()\n",
    "            < row[metric][\"upper_ci\"]\n",
    "        )\n",
    "        or (\n",
    "            row[metric][\"mean\"]\n",
    "            > table.loc[row[\"group_max\"], (metric, \"lower_ci\")].squeeze()\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    table[\"result\"] = table.apply(format_result, axis=1)\n",
    "    if bold:\n",
    "        table[\"result\"] = table.apply(bold_result, axis=1)\n",
    "\n",
    "    if latex:\n",
    "        table[\"result\"] = table.apply(lambda row: \"$\" + row[\"result\"] + \"$\", axis=1)\n",
    "\n",
    "    table[\"count\"] = table[(metric, \"count\")]\n",
    "\n",
    "    return table\n",
    "    cols = (\n",
    "        [\"method\", \"dataset\", \"group\"] if show_group else [\"method\", \"dataset\", \"count\"]\n",
    "    )\n",
    "    table_flat = table[cols].pivot(index=\"method\", columns=\"dataset\")\n",
    "\n",
    "    return table_flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = api.runs(\n",
    "    \"emilem/equiv-stochastic-diffusion-processes\",\n",
    "    filters={\n",
    "        \"createdAt\": {\"$gte\": \"2023-04-20T00:00:00.000Z\"}\n",
    "        # 'config.name': 'fire's\n",
    "    },\n",
    ")\n",
    "\n",
    "summary_list, config_list, name_list = [], [], []\n",
    "\n",
    "rows = []\n",
    "\n",
    "for run in runs:\n",
    "    # .summary contains the output keys/values for metrics like accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    summary_list.append(run.summary._json_dict)\n",
    "\n",
    "    # config = {\"config/\" + k: v for k, v in run.config.items() if not k.startswith(\"_\")}\n",
    "    config = {k: v for k, v in run.config.items() if not k.startswith(\"_\")}\n",
    "\n",
    "    # .name is the human-readable name of the run.\n",
    "    name_list.append(run.name)\n",
    "\n",
    "    rows.append(\n",
    "        {\n",
    "            \"group\": run.group,\n",
    "            **run.summary._json_dict,\n",
    "            **config,\n",
    "        }\n",
    "    )\n",
    "\n",
    "runs_df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_method(row):\n",
    "    if \"MultiOutputAttentionModel\" in row[\"net\"]:\n",
    "        if \"RBFVec\" in row[\"kernel\"]:\n",
    "            return \"NDP (SE)\"\n",
    "        elif \"WhiteVec\" in row[\"kernel\"]:\n",
    "            return \"NDP (White)\"\n",
    "        else:\n",
    "            raise\n",
    "    elif \"TransformerModule\" in row[\"net\"]:\n",
    "        if row[\"net/attention\"] == True:\n",
    "            return \"SE(3)-Transformer\"\n",
    "        else:\n",
    "            return \"Tensor Field\"\n",
    "\n",
    "# runs_df = runs_df.dropna()\n",
    "\n",
    "runs_df[\"kernel\"] = runs_df[\"sde/limiting_kernel/_target_\"]\n",
    "runs_df[\"net\"] = runs_df[\"net/_target_\"]\n",
    "runs_df = runs_df[~runs_df[\"kernel\"].isna()]\n",
    "runs_df[\"method\"] = runs_df.apply(make_method, axis=1)\n",
    "runs_df[\"dataset\"] = runs_df[\"data/kernel/_target_\"].replace(\n",
    "    {\n",
    "        \"neural_diffusion_processes.kernels.RBFDivFree\": \"Div-free\",\n",
    "        \"neural_diffusion_processes.kernels.RBFCurlFree\": \"Curl-free\",\n",
    "        \"neural_diffusion_processes.kernels.RBFVec\": \"SE\",\n",
    "    }\n",
    ")\n",
    "runs_df[\"lengthscale\"] = runs_df[\"kernel/params/lengthscale\"]\n",
    "runs_df[\"variance\"] = runs_df[\"kernel/params/variance\"]\n",
    "runs_df[\"noise\"] = runs_df[\"kernel/noise\"]\n",
    "runs_df[\"beta1\"] = runs_df[\"beta_schedule/beta1\"]\n",
    "runs_df[\"std_trick\"] = runs_df[\"sde/std_trick\"]\n",
    "runs_df[\"residual_trick\"] = runs_df[\"sde/residual_trick\"]\n",
    "runs_df[\"is_score_preconditioned\"] = runs_df[\"sde/is_score_preconditioned\"]\n",
    "runs_df[\"n_points\"] = runs_df[\"data/n_points\"].apply(lambda x: str(x))\n",
    "\n",
    "\n",
    "def query(data_frame, query_string):\n",
    "    if query_string == \"all\":\n",
    "        return data_frame\n",
    "    return data_frame.query(query_string)\n",
    "\n",
    "\n",
    "criteria = [\n",
    "    # \"`name` == 'context'\",\n",
    "    \"`lengthscale` == 1.\",\n",
    "    \"`variance` == 1.\",\n",
    "    \"`beta1` == 15\",\n",
    "    # \"`noise` == 0.1\",\n",
    "    # \"`optim/n_steps` == 100000\",\n",
    "    \"(`data/n_train` == 80000. | `data/num_samples_train` == 80000.)\",\n",
    "    \"`n_points` == '[25, 648]'\",\n",
    "]\n",
    "criteria = [\"all\"] if criteria == [] else criteria\n",
    "runs_df = query(runs_df, \" & \".join(criteria))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metric = \"cond_logp\"\n",
    "val_metric = \"cond_logp\"\n",
    "results = runs_df.query(\"\")\n",
    "\n",
    "results = (\n",
    "        results.groupby(by=[\"method\", \"dataset\", \"data/n_train\"])\n",
    "        .agg(\n",
    "            {\n",
    "                metric: [\"mean\", \"std\", \"sem\"],\n",
    "                val_metric: [\"mean\", \"std\", \"sem\"],\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(8 * 2, 8 * 2))\n",
    "fig.subplots_adjust(wspace=0, hspace=0.0)\n",
    "for i, method in enumerate([\"NDP (White)\", \"Tensor Field\", \"SE(3)-Transformer\"]):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually adding the CNP results!\n",
    "\n",
    "columns = ['group', 'method', \"config/seed\", 'dataset', 'cond_logp']\n",
    "rows = [\n",
    "    [\"ConvCNP\", \"ConvCNP\", 1, \"Curl-free\", -1.7677894592285157],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 2, \"Curl-free\", -1.7930784861246745],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 3, \"Curl-free\", -1.7732168833414714],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 4, \"Curl-free\", -1.7641785939534504],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 5, \"Curl-free\", -1.7661763509114583],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 1, \"Div-free\", -1.7574120839436849],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 2, \"Div-free\", -1.7526724497477213],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 3, \"Div-free\", -1.7614798227945963],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 4, \"Div-free\", -1.7596895853678385],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 5, \"Div-free\", -1.7613946278889974],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 1, \"SE\", -1.7010875701904298],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 2, \"SE\", -1.7113407135009766],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 3, \"SE\", -1.7199483235677084],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 4, \"SE\", -1.7112767537434896],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 5, \"SE\", -1.6989725748697917],\n",
    "    [\"C4\", \"SteerCNP\", 1, \"Curl-free\", -1.5672126770019532],\n",
    "    [\"C4\", \"SteerCNP\", 2, \"Curl-free\", -1.5728504180908203],\n",
    "    [\"C4\", \"SteerCNP\", 3, \"Curl-free\", -1.5713305155436197],\n",
    "    [\"C4\", \"SteerCNP\", 4, \"Curl-free\", -1.5724315643310547],\n",
    "    [\"C4\", \"SteerCNP\", 5, \"Curl-free\", -1.5712619781494142],\n",
    "    [\"C4\", \"SteerCNP\", 1, \"Div-free\", -1.5733726501464844],\n",
    "    [\"C4\", \"SteerCNP\", 2, \"Div-free\", -1.5614351908365884],\n",
    "    [\"C4\", \"SteerCNP\", 3, \"Div-free\", -1.574195353190104],\n",
    "    [\"C4\", \"SteerCNP\", 4, \"Div-free\", -1.5771334330240885],\n",
    "    [\"C4\", \"SteerCNP\", 1, \"SE\", -1.6106020609537761],\n",
    "    [\"C4\", \"SteerCNP\", 2, \"SE\", -1.6136614481608074],\n",
    "    [\"C4\", \"SteerCNP\", 3, \"SE\", -1.6125297546386719],\n",
    "    [\"C4\", \"SteerCNP\", 4, \"SE\", -1.6106975555419922],\n",
    "    [\"C4\", \"SteerCNP\", 5, \"SE\", -1.6165941874186198],\n",
    "    [\"GP\", \"GP\", 1, \"Curl-free\", 0.6598717212677002],\n",
    "    [\"GP\", \"GP\", 2, \"Curl-free\", 0.6598289966583252],\n",
    "    [\"GP\", \"GP\", 3, \"Curl-free\", 0.6598330497741699],\n",
    "    [\"GP\", \"GP\", 4, \"Curl-free\", 0.6598613739013672],\n",
    "    [\"GP\", \"GP\", 5, \"Curl-free\", 0.6598188877105713],\n",
    "    [\"GP\", \"GP\", 1, \"Div-free\", 0.6602359294891358],\n",
    "    [\"GP\", \"GP\", 2, \"Div-free\", 0.6602742195129394],\n",
    "    [\"GP\", \"GP\", 3, \"Div-free\", 0.6602205753326416],\n",
    "    [\"GP\", \"GP\", 4, \"Div-free\", 0.6602634906768798],\n",
    "    [\"GP\", \"GP\", 5, \"Div-free\", 0.6602737426757812],\n",
    "    [\"GP\", \"GP\", 1, \"SE\", 0.5573758125305176],\n",
    "    [\"GP\", \"GP\", 2, \"SE\", 0.5573612689971924],\n",
    "    [\"GP\", \"GP\", 3, \"SE\", 0.5573762893676758],\n",
    "    [\"GP\", \"GP\", 4, \"SE\", 0.5574379444122315],\n",
    "    [\"GP\", \"GP\", 5, \"SE\", 0.5574140071868896],\n",
    "    [\"GP\", \"GP (diag.)\", 1, \"Curl-free\", -1.4716421127319337],\n",
    "    [\"GP\", \"GP (diag.)\", 2, \"Curl-free\", -1.4714653968811036],\n",
    "    [\"GP\", \"GP (diag.)\", 3, \"Curl-free\", -1.4716914176940918],\n",
    "    [\"GP\", \"GP (diag.)\", 4, \"Curl-free\", -1.471421241760254],\n",
    "    [\"GP\", \"GP (diag.)\", 5, \"Curl-free\", -1.471923542022705],\n",
    "    [\"GP\", \"GP (diag.)\", 1, \"Div-free\", -1.466759204864502],\n",
    "    [\"GP\", \"GP (diag.)\", 2, \"Div-free\", -1.4690001487731934],\n",
    "    [\"GP\", \"GP (diag.)\", 3, \"Div-free\", -1.4697052001953126],\n",
    "    [\"GP\", \"GP (diag.)\", 4, \"Div-free\", -1.4679842948913575],\n",
    "    [\"GP\", \"GP (diag.)\", 5, \"Div-free\", -1.4686187744140624],\n",
    "    [\"GP\", \"GP (diag.)\", 1, \"SE\", -1.559639072418213],\n",
    "    [\"GP\", \"GP (diag.)\", 2, \"SE\", -1.5616438865661622],\n",
    "    [\"GP\", \"GP (diag.)\", 3, \"SE\", -1.5610824584960938],\n",
    "    [\"GP\", \"GP (diag.)\", 4, \"SE\", -1.5596550941467284],\n",
    "    [\"GP\", \"GP (diag.)\", 5, \"SE\", -1.5608834266662597],\n",
    "    ]\n",
    "cnp_runs_df = pd.DataFrame(rows, columns=columns)\n",
    "runs_df = pd.concat([runs_df, cnp_runs_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  group  \\\n",
      "                                                                                                          \n",
      "0                                                                                                    C4   \n",
      "1                                                                                                    C4   \n",
      "2                                                                                                    C4   \n",
      "3                                                                                               ConvCNP   \n",
      "4                                                                                               ConvCNP   \n",
      "5                                                                                               ConvCNP   \n",
      "6   context_data.n_points=[25,648],data.n_train=80000,data_kernel=curlfree,net.attention=False,net=e3nn   \n",
      "7    context_data.n_points=[25,648],data.n_train=80000,data_kernel=curlfree,net.attention=True,net=e3nn   \n",
      "8                      context_data.n_points=[25,648],data.n_train=80000,data_kernel=curlfree,net=mattn   \n",
      "10        context_data.n_points=[25,648],data.n_train=80000,data_kernel=divfree,kernel=rbfvec,net=mattn   \n",
      "11   context_data.n_points=[25,648],data.n_train=80000,data_kernel=divfree,net.attention=false,net=e3nn   \n",
      "14         context_data.n_points=[25,648],data.n_train=80000,data_kernel=rbfvec,kernel=rbfvec,net=mattn   \n",
      "15    context_data.n_points=[25,648],data.n_train=80000,data_kernel=rbfvec,net.attention=False,net=e3nn   \n",
      "16     context_data.n_points=[25,648],data.n_train=80000,data_kernel=rbfvec,net.attention=True,net=e3nn   \n",
      "17                       context_data.n_points=[25,648],data.n_train=80000,data_kernel=rbfvec,net=mattn   \n",
      "20                                                            contexts_data.n_points=[25,648],net=mattn   \n",
      "\n",
      "                     result  \n",
      "                             \n",
      "0      ${-1.57_{\\pm 0.00}}$  \n",
      "1      ${-1.57_{\\pm 0.01}}$  \n",
      "2      ${-1.61_{\\pm 0.00}}$  \n",
      "3      ${-1.77_{\\pm 0.01}}$  \n",
      "4      ${-1.76_{\\pm 0.00}}$  \n",
      "5      ${-1.71_{\\pm 0.01}}$  \n",
      "6    $\\bm{0.65_{\\pm 0.01}}$  \n",
      "7    $\\bm{0.64_{\\pm 0.02}}$  \n",
      "8       ${0.62_{\\pm 0.01}}$  \n",
      "10  $\\bm{-0.48_{\\pm 1.37}}$  \n",
      "11   $\\bm{0.66_{\\pm 0.01}}$  \n",
      "14     ${-0.00_{\\pm 0.05}}$  \n",
      "15   $\\bm{0.56_{\\pm 0.01}}$  \n",
      "16       ${0.55_{\\pm nan}}$  \n",
      "17      ${0.55_{\\pm 0.00}}$  \n",
      "20       ${0.62_{\\pm nan}}$  \n",
      "\\textsc{Model}                         \\scshape SE      \\scshape Curl-free  \\\n",
      "\\scshape ConvCNP              ${-1.71_{\\pm 0.01}}$    ${-1.77_{\\pm 0.01}}$   \n",
      "\\scshape SteerCNP             ${-1.61_{\\pm 0.00}}$    ${-1.57_{\\pm 0.00}}$   \n",
      "\\scshape NDP (White)           ${0.55_{\\pm 0.00}}$     ${0.62_{\\pm 0.01}}$   \n",
      "\\scshape SE(3)-Transformer      ${0.55_{\\pm nan}}$  $\\bm{0.64_{\\pm 0.02}}$   \n",
      "\\scshape Tensor Field       $\\bm{0.56_{\\pm 0.01}}$  $\\bm{0.65_{\\pm 0.01}}$   \n",
      "\n",
      "\\textsc{Model}                   \\scshape Div-free  \n",
      "\\scshape ConvCNP              ${-1.76_{\\pm 0.00}}$  \n",
      "\\scshape SteerCNP             ${-1.57_{\\pm 0.01}}$  \n",
      "\\scshape NDP (White)            ${0.62_{\\pm nan}}$  \n",
      "\\scshape SE(3)-Transformer                     NaN  \n",
      "\\scshape Tensor Field       $\\bm{0.66_{\\pm 0.01}}$  \n",
      "/homes/ebm32/score-sde/experiments/steerable_gp/table.tex\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>\\textsc{Model}</th>\n",
       "      <th>\\scshape SE</th>\n",
       "      <th>\\scshape Curl-free</th>\n",
       "      <th>\\scshape Div-free</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\\scshape ConvCNP</th>\n",
       "      <td>${-1.71_{\\pm 0.01}}$</td>\n",
       "      <td>${-1.77_{\\pm 0.01}}$</td>\n",
       "      <td>${-1.76_{\\pm 0.00}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\scshape SteerCNP</th>\n",
       "      <td>${-1.61_{\\pm 0.00}}$</td>\n",
       "      <td>${-1.57_{\\pm 0.00}}$</td>\n",
       "      <td>${-1.57_{\\pm 0.01}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\scshape GP (diag.)</th>\n",
       "      <td>${-1.56_{\\pm 0.00}}$</td>\n",
       "      <td>${-1.47_{\\pm 0.00}}$</td>\n",
       "      <td>${-1.47_{\\pm 0.00}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\scshape NDP (White)</th>\n",
       "      <td>${0.55_{\\pm 0.00}}$</td>\n",
       "      <td>${0.62_{\\pm 0.01}}$</td>\n",
       "      <td>${0.62_{\\pm nan}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\scshape SE(3)-Transformer</th>\n",
       "      <td>${0.55_{\\pm nan}}$</td>\n",
       "      <td>$\\bm{0.64_{\\pm 0.02}}$</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\scshape Tensor Field</th>\n",
       "      <td>$\\bm{0.56_{\\pm 0.01}}$</td>\n",
       "      <td>$\\bm{0.65_{\\pm 0.01}}$</td>\n",
       "      <td>$\\bm{0.66_{\\pm 0.01}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\scshape GP</th>\n",
       "      <td>${0.56_{\\pm 0.00}}$</td>\n",
       "      <td>${0.66_{\\pm 0.00}}$</td>\n",
       "      <td>${0.66_{\\pm 0.00}}$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "\\textsc{Model}                         \\scshape SE      \\scshape Curl-free  \\\n",
       "\\scshape ConvCNP              ${-1.71_{\\pm 0.01}}$    ${-1.77_{\\pm 0.01}}$   \n",
       "\\scshape SteerCNP             ${-1.61_{\\pm 0.00}}$    ${-1.57_{\\pm 0.00}}$   \n",
       "\\scshape GP (diag.)           ${-1.56_{\\pm 0.00}}$    ${-1.47_{\\pm 0.00}}$   \n",
       "\\scshape NDP (White)           ${0.55_{\\pm 0.00}}$     ${0.62_{\\pm 0.01}}$   \n",
       "\\scshape SE(3)-Transformer      ${0.55_{\\pm nan}}$  $\\bm{0.64_{\\pm 0.02}}$   \n",
       "\\scshape Tensor Field       $\\bm{0.56_{\\pm 0.01}}$  $\\bm{0.65_{\\pm 0.01}}$   \n",
       "\\scshape GP                    ${0.56_{\\pm 0.00}}$     ${0.66_{\\pm 0.00}}$   \n",
       "\n",
       "\\textsc{Model}                   \\scshape Div-free  \n",
       "\\scshape ConvCNP              ${-1.76_{\\pm 0.00}}$  \n",
       "\\scshape SteerCNP             ${-1.57_{\\pm 0.01}}$  \n",
       "\\scshape GP (diag.)           ${-1.47_{\\pm 0.00}}$  \n",
       "\\scshape NDP (White)            ${0.62_{\\pm nan}}$  \n",
       "\\scshape SE(3)-Transformer                     NaN  \n",
       "\\scshape Tensor Field       $\\bm{0.66_{\\pm 0.01}}$  \n",
       "\\scshape GP                    ${0.66_{\\pm 0.00}}$  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format(table, row_names=[]):\n",
    "    cols = [\"method\", \"dataset\", \"result\"]\n",
    "    table = table[cols].pivot(index=\"method\", columns=\"dataset\")\n",
    "    if len(row_names) > 0:\n",
    "        table = table.reindex(row_names)\n",
    "    table.index = [f\"\\\\scshape {x}\" for x in table.index]\n",
    "\n",
    "    table = table.droplevel(level=0, axis=1)\n",
    "    table = table.droplevel(level=0, axis=1)\n",
    "    table = table[[\"SE\", \"Curl-free\", \"Div-free\"]]\n",
    "    table.columns = [f\"\\\\scshape {x}\" for x in table.columns]\n",
    "    table.columns.name = \"\\\\textsc{Model}\"\n",
    "    table.index.name = None\n",
    "    return table\n",
    "\n",
    "metric = \"cond_logp\"\n",
    "# metric = \"prior_logp\"\n",
    "# metric = \"true_logp\"\n",
    "\n",
    "non_gp_idx = runs_df[\"method\"].isin([\"GP\", \"GP (diag.)\"])\n",
    "\n",
    "test_table = make_table_from_metric(\n",
    "    metric, runs_df[~non_gp_idx], val_metric=metric, drop_nans=False, latex=True, bold=True, show_group=False, select_best=True\n",
    ")\n",
    "\n",
    "print(test_table[[\"group\", \"result\"]])\n",
    "table = format(test_table, row_names=[\"ConvCNP\", \"SteerCNP\", \"NDP (White)\", \"SE(3)-Transformer\", \"Tensor Field\"])\n",
    "print(table)\n",
    "gp_test_table = make_table_from_metric(\n",
    "    metric, runs_df[non_gp_idx], val_metric=metric, drop_nans=False, latex=True, bold=False, show_group=False, select_best=True, pm=True\n",
    ")\n",
    "# # print(gp_test_table)\n",
    "gp_table = format(gp_test_table, row_names=[\"GP (diag.)\", \"GP\"])\n",
    "table = pd.concat([table, gp_table])\n",
    "row_names = [\"ConvCNP\", \"SteerCNP\", \"GP (diag.)\", \"NDP (White)\", \"SE(3)-Transformer\", \"Tensor Field\", \"GP\"]\n",
    "table = table.reindex([f\"\\\\scshape {row}\" for row in row_names])\n",
    "\n",
    "import os\n",
    "latex_path = \"table.tex\"\n",
    "filename = os.path.join(os.getcwd(), latex_path)\n",
    "print(filename)\n",
    "table.style.to_latex(\n",
    "    buf=filename, hrules=True, multicol_align=\"c\", column_format=\"lrrr\"\n",
    ")\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C4</td>\n",
       "      <td>${-1.57_{\\pm 0.00}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C4</td>\n",
       "      <td>${-1.57_{\\pm 0.01}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C4</td>\n",
       "      <td>${-1.61_{\\pm 0.00}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ConvCNP</td>\n",
       "      <td>${-1.77_{\\pm 0.01}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ConvCNP</td>\n",
       "      <td>${-1.76_{\\pm 0.00}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ConvCNP</td>\n",
       "      <td>${-1.71_{\\pm 0.01}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GP</td>\n",
       "      <td>$\\bm{0.66_{\\pm 0.00}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GP</td>\n",
       "      <td>$\\bm{0.66_{\\pm 0.00}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GP</td>\n",
       "      <td>$\\bm{0.56_{\\pm 0.00}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GP</td>\n",
       "      <td>${-1.47_{\\pm 0.00}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GP</td>\n",
       "      <td>${-1.47_{\\pm 0.00}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GP</td>\n",
       "      <td>${-1.56_{\\pm 0.00}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>context_data.n_points=[25,648],data.n_train=80000,data_kernel=curlfree,net.attention=False,net=e3nn</td>\n",
       "      <td>$\\bm{0.65_{\\pm 0.01}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>context_data.n_points=[25,648],data.n_train=80000,data_kernel=curlfree,net.attention=True,net=e3nn</td>\n",
       "      <td>$\\bm{0.64_{\\pm 0.02}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>context_data.n_points=[25,648],data.n_train=80000,data_kernel=curlfree,net=mattn</td>\n",
       "      <td>${0.62_{\\pm 0.01}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>context_data.n_points=[25,648],data.n_train=80000,data_kernel=divfree,kernel=rbfvec,net.attention=False,net=e3nn</td>\n",
       "      <td>${0.64_{\\pm 0.01}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>context_data.n_points=[25,648],data.n_train=80000,data_kernel=divfree,kernel=rbfvec,net=mattn</td>\n",
       "      <td>$\\bm{-0.48_{\\pm 1.37}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>context_data.n_points=[25,648],data.n_train=80000,data_kernel=divfree,net.attention=false,net=e3nn</td>\n",
       "      <td>$\\bm{0.66_{\\pm 0.01}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>context_data.n_points=[25,648],data.n_train=80000,data_kernel=divfree,net=mattn</td>\n",
       "      <td>${0.62_{\\pm 0.01}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>context_data.n_points=[25,648],data.n_train=80000,data_kernel=rbfvec,kernel=rbfvec,net.attention=False,net=e3nn</td>\n",
       "      <td>${0.55_{\\pm 0.00}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>context_data.n_points=[25,648],data.n_train=80000,data_kernel=rbfvec,kernel=rbfvec,net=mattn</td>\n",
       "      <td>${-0.00_{\\pm 0.05}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>context_data.n_points=[25,648],data.n_train=80000,data_kernel=rbfvec,net.attention=False,net=e3nn</td>\n",
       "      <td>$\\bm{0.56_{\\pm 0.01}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>context_data.n_points=[25,648],data.n_train=80000,data_kernel=rbfvec,net.attention=True,net=e3nn</td>\n",
       "      <td>${0.55_{\\pm nan}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>context_data.n_points=[25,648],data.n_train=80000,data_kernel=rbfvec,net=mattn</td>\n",
       "      <td>${0.55_{\\pm 0.00}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>context_data.n_points=[25,648],data.n_train=80000,net.attention=True,net=e3nn</td>\n",
       "      <td>${nan_{\\pm nan}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>context_data.n_points=[25,648],net.attention=false,net=e3nn,optim.batch_size=30</td>\n",
       "      <td>${0.64_{\\pm nan}}$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>contexts_data.n_points=[25,648],net=mattn</td>\n",
       "      <td>${0.62_{\\pm nan}}$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                               group  \\\n",
       "                                                                                                                       \n",
       "0                                                                                                                 C4   \n",
       "1                                                                                                                 C4   \n",
       "2                                                                                                                 C4   \n",
       "3                                                                                                            ConvCNP   \n",
       "4                                                                                                            ConvCNP   \n",
       "5                                                                                                            ConvCNP   \n",
       "6                                                                                                                 GP   \n",
       "7                                                                                                                 GP   \n",
       "8                                                                                                                 GP   \n",
       "9                                                                                                                 GP   \n",
       "10                                                                                                                GP   \n",
       "11                                                                                                                GP   \n",
       "12               context_data.n_points=[25,648],data.n_train=80000,data_kernel=curlfree,net.attention=False,net=e3nn   \n",
       "13                context_data.n_points=[25,648],data.n_train=80000,data_kernel=curlfree,net.attention=True,net=e3nn   \n",
       "14                                  context_data.n_points=[25,648],data.n_train=80000,data_kernel=curlfree,net=mattn   \n",
       "15  context_data.n_points=[25,648],data.n_train=80000,data_kernel=divfree,kernel=rbfvec,net.attention=False,net=e3nn   \n",
       "16                     context_data.n_points=[25,648],data.n_train=80000,data_kernel=divfree,kernel=rbfvec,net=mattn   \n",
       "17                context_data.n_points=[25,648],data.n_train=80000,data_kernel=divfree,net.attention=false,net=e3nn   \n",
       "18                                   context_data.n_points=[25,648],data.n_train=80000,data_kernel=divfree,net=mattn   \n",
       "19   context_data.n_points=[25,648],data.n_train=80000,data_kernel=rbfvec,kernel=rbfvec,net.attention=False,net=e3nn   \n",
       "20                      context_data.n_points=[25,648],data.n_train=80000,data_kernel=rbfvec,kernel=rbfvec,net=mattn   \n",
       "21                 context_data.n_points=[25,648],data.n_train=80000,data_kernel=rbfvec,net.attention=False,net=e3nn   \n",
       "22                  context_data.n_points=[25,648],data.n_train=80000,data_kernel=rbfvec,net.attention=True,net=e3nn   \n",
       "23                                    context_data.n_points=[25,648],data.n_train=80000,data_kernel=rbfvec,net=mattn   \n",
       "24                                     context_data.n_points=[25,648],data.n_train=80000,net.attention=True,net=e3nn   \n",
       "25                                   context_data.n_points=[25,648],net.attention=false,net=e3nn,optim.batch_size=30   \n",
       "26                                                                         contexts_data.n_points=[25,648],net=mattn   \n",
       "\n",
       "                     result  \n",
       "                             \n",
       "0      ${-1.57_{\\pm 0.00}}$  \n",
       "1      ${-1.57_{\\pm 0.01}}$  \n",
       "2      ${-1.61_{\\pm 0.00}}$  \n",
       "3      ${-1.77_{\\pm 0.01}}$  \n",
       "4      ${-1.76_{\\pm 0.00}}$  \n",
       "5      ${-1.71_{\\pm 0.01}}$  \n",
       "6    $\\bm{0.66_{\\pm 0.00}}$  \n",
       "7    $\\bm{0.66_{\\pm 0.00}}$  \n",
       "8    $\\bm{0.56_{\\pm 0.00}}$  \n",
       "9      ${-1.47_{\\pm 0.00}}$  \n",
       "10     ${-1.47_{\\pm 0.00}}$  \n",
       "11     ${-1.56_{\\pm 0.00}}$  \n",
       "12   $\\bm{0.65_{\\pm 0.01}}$  \n",
       "13   $\\bm{0.64_{\\pm 0.02}}$  \n",
       "14      ${0.62_{\\pm 0.01}}$  \n",
       "15      ${0.64_{\\pm 0.01}}$  \n",
       "16  $\\bm{-0.48_{\\pm 1.37}}$  \n",
       "17   $\\bm{0.66_{\\pm 0.01}}$  \n",
       "18      ${0.62_{\\pm 0.01}}$  \n",
       "19      ${0.55_{\\pm 0.00}}$  \n",
       "20     ${-0.00_{\\pm 0.05}}$  \n",
       "21   $\\bm{0.56_{\\pm 0.01}}$  \n",
       "22       ${0.55_{\\pm nan}}$  \n",
       "23      ${0.55_{\\pm 0.00}}$  \n",
       "24        ${nan_{\\pm nan}}$  \n",
       "25       ${0.64_{\\pm nan}}$  \n",
       "26       ${0.62_{\\pm nan}}$  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = make_table_from_metric(\n",
    "    \"cond_logp\", runs_df, val_metric=\"cond_logp\", drop_nans=False, latex=True, bold=True, show_group=False, select_best=False\n",
    ")\n",
    "# with pd.option_context('display.max_colwidth', None):\n",
    "pd.options.display.max_colwidth=None\n",
    "table[[\"group\", \"result\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
