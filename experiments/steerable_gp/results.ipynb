{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_table_from_metric(\n",
    "    metric,\n",
    "    results,\n",
    "    val_metric=None,\n",
    "    ci=0.95,\n",
    "    latex=False,\n",
    "    bold=True,\n",
    "    drop_nans=False,\n",
    "    show_group=False,\n",
    "    select_best=True,\n",
    "    pm=True,\n",
    "    uncertainty='half_ci'\n",
    "):\n",
    "    if val_metric is None:\n",
    "        val_metric = metric\n",
    "\n",
    "    alpha = (1 - ci) / 2\n",
    "\n",
    "    if drop_nans:\n",
    "        results = results[results[metric].notna()]\n",
    "        results = results[results[val_metric].notna()]\n",
    "\n",
    "    def half_ci(group):\n",
    "        data = group.to_numpy()\n",
    "        sem = stats.sem(data)\n",
    "        t2 = stats.t.ppf(1 - alpha, len(data) - 1) - stats.t.ppf(alpha, len(data) - 1)\n",
    "        return sem * (t2 / 2)\n",
    "        # return np.std(data)\n",
    "\n",
    "    def lower_ci(group):\n",
    "        data = group.to_numpy()\n",
    "        sem = stats.sem(data)\n",
    "        mean = data.mean()\n",
    "        t = stats.t.ppf(alpha, len(data) - 1)\n",
    "        return mean + sem * t\n",
    "\n",
    "    def upper_ci(group):\n",
    "        data = group.to_numpy()\n",
    "        sem = stats.sem(data)\n",
    "        mean = data.mean()\n",
    "        t = stats.t.ppf(1 - alpha, len(data) - 1)\n",
    "        return mean + sem * t\n",
    "\n",
    "    def count(group):\n",
    "        data = group.to_numpy()\n",
    "        return np.prod(data.shape)\n",
    "    \n",
    "\n",
    "    results = (\n",
    "        results.groupby(by=[\"group\", \"method\", \"dataset\"])\n",
    "        .agg(\n",
    "            {\n",
    "                metric: [\"mean\", \"std\", \"sem\", lower_ci, upper_ci, half_ci, count],\n",
    "                val_metric: [\n",
    "                    \"mean\",\n",
    "                    \"std\",\n",
    "                    \"sem\",\n",
    "                    lower_ci,\n",
    "                    upper_ci,\n",
    "                    half_ci,\n",
    "                    count,\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    if select_best:\n",
    "        group_max_idx = (\n",
    "            results.groupby(by=[\"method\", \"dataset\"]).transform(max)[val_metric][\"mean\"]\n",
    "            == results[val_metric][\"mean\"]\n",
    "        )\n",
    "        table = results[group_max_idx]\n",
    "    else:\n",
    "        table = results\n",
    "\n",
    "    # table = table[table[\"dataset\"].isin([\"Earthquake\", \"Fire\", \"Flood\", \"Volcano\"])]\n",
    "\n",
    "    if latex:\n",
    "\n",
    "        def format_result(row):\n",
    "            if pm:\n",
    "                return (\n",
    "                    f\"{{{row[metric]['mean']:0.2f}_{{\\pm {row[metric][uncertainty]:0.2f}}}}}\"\n",
    "                )\n",
    "            else:\n",
    "                return f\"{{{row[metric]['mean']:0.2f}}}\"\n",
    "\n",
    "\n",
    "        def bold_result(row):\n",
    "            return \"\\\\bm\" + row[\"result\"] if row[\"bold\"].any() else row[\"result\"]\n",
    "\n",
    "    else:\n",
    "\n",
    "        def format_result(row):\n",
    "            if pm:\n",
    "                return f\"{row[metric]['mean']:0.2f} Â± {row[metric][uncertainty]:0.2f}\"\n",
    "            else:\n",
    "                return f\"{row[metric]['mean']:0.2f}\"\n",
    "\n",
    "        def bold_result(row):\n",
    "            return \"* \" + row[\"result\"] if row[\"bold\"].any() else row[\"result\"]\n",
    "\n",
    "    table[\"group_max\"] = table.groupby(by=[\"dataset\"]).transform(max)[metric][\"mean\"]\n",
    "    table[\"group_max\"] = table.apply(\n",
    "        lambda row: table.index[table[metric][\"mean\"] == row[\"group_max\"].squeeze()][0],\n",
    "        axis=1,\n",
    "    )\n",
    "    table[\"bold\"] = table.apply(\n",
    "        lambda row: (\n",
    "            table.loc[row[\"group_max\"], (metric, \"mean\")].squeeze()\n",
    "            < row[metric][\"upper_ci\"]\n",
    "        )\n",
    "        or (\n",
    "            row[metric][\"mean\"]\n",
    "            > table.loc[row[\"group_max\"], (metric, \"lower_ci\")].squeeze()\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    table[\"result\"] = table.apply(format_result, axis=1)\n",
    "    if bold:\n",
    "        table[\"result\"] = table.apply(bold_result, axis=1)\n",
    "\n",
    "    if latex:\n",
    "        table[\"result\"] = table.apply(lambda row: \"$\" + row[\"result\"] + \"$\", axis=1)\n",
    "\n",
    "    table[\"count\"] = table[(metric, \"count\")]\n",
    "\n",
    "    return table\n",
    "    cols = (\n",
    "        [\"method\", \"dataset\", \"group\"] if show_group else [\"method\", \"dataset\", \"count\"]\n",
    "    )\n",
    "    table_flat = table[cols].pivot(index=\"method\", columns=\"dataset\")\n",
    "\n",
    "    return table_flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = api.runs(\n",
    "    \"emilem/equiv-stochastic-diffusion-processes\",\n",
    "    filters={\n",
    "        \"createdAt\": {\"$gte\": \"2023-04-20T00:00:00.000Z\"}\n",
    "        # 'config.name': 'fire's\n",
    "    },\n",
    ")\n",
    "\n",
    "summary_list, config_list, name_list = [], [], []\n",
    "\n",
    "rows = []\n",
    "\n",
    "for run in runs:\n",
    "    # .summary contains the output keys/values for metrics like accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    summary_list.append(run.summary._json_dict)\n",
    "\n",
    "    # config = {\"config/\" + k: v for k, v in run.config.items() if not k.startswith(\"_\")}\n",
    "    config = {k: v for k, v in run.config.items() if not k.startswith(\"_\")}\n",
    "\n",
    "    # .name is the human-readable name of the run.\n",
    "    name_list.append(run.name)\n",
    "\n",
    "    rows.append(\n",
    "        {\n",
    "            \"group\": run.group,\n",
    "            **run.summary._json_dict,\n",
    "            **config,\n",
    "        }\n",
    "    )\n",
    "\n",
    "runs_df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_method(row):\n",
    "    if \"MultiOutputAttentionModel\" in row[\"net\"]:\n",
    "        if \"RBFVec\" in row[\"kernel\"]:\n",
    "            return \"NDP (SE)\"\n",
    "        elif \"WhiteVec\" in row[\"kernel\"]:\n",
    "            return \"NDP (White)\"\n",
    "        else:\n",
    "            raise\n",
    "    elif \"TransformerModule\" in row[\"net\"]:\n",
    "        if row[\"net/attention\"] == True:\n",
    "            return \"SE(3)-Transformer\"\n",
    "        else:\n",
    "            return \"Tensor Field\"\n",
    "\n",
    "# runs_df = runs_df.dropna()\n",
    "\n",
    "runs_df[\"kernel\"] = runs_df[\"sde/limiting_kernel/_target_\"]\n",
    "runs_df[\"net\"] = runs_df[\"net/_target_\"]\n",
    "runs_df = runs_df[~runs_df[\"kernel\"].isna()]\n",
    "runs_df[\"method\"] = runs_df.apply(make_method, axis=1)\n",
    "runs_df[\"dataset\"] = runs_df[\"data/kernel/_target_\"].replace(\n",
    "    {\n",
    "        \"neural_diffusion_processes.kernels.RBFDivFree\": \"Div-free\",\n",
    "        \"neural_diffusion_processes.kernels.RBFCurlFree\": \"Curl-free\",\n",
    "        \"neural_diffusion_processes.kernels.RBFVec\": \"SE\",\n",
    "    }\n",
    ")\n",
    "runs_df[\"lengthscale\"] = runs_df[\"kernel/params/lengthscale\"]\n",
    "runs_df[\"variance\"] = runs_df[\"kernel/params/variance\"]\n",
    "runs_df[\"noise\"] = runs_df[\"kernel/noise\"]\n",
    "runs_df[\"beta1\"] = runs_df[\"beta_schedule/beta1\"]\n",
    "runs_df[\"std_trick\"] = runs_df[\"sde/std_trick\"]\n",
    "runs_df[\"residual_trick\"] = runs_df[\"sde/residual_trick\"]\n",
    "runs_df[\"is_score_preconditioned\"] = runs_df[\"sde/is_score_preconditioned\"]\n",
    "runs_df[\"n_points\"] = runs_df[\"data/n_points\"].apply(lambda x: str(x))\n",
    "\n",
    "\n",
    "def query(data_frame, query_string):\n",
    "    if query_string == \"all\":\n",
    "        return data_frame\n",
    "    return data_frame.query(query_string)\n",
    "\n",
    "\n",
    "criteria = [\n",
    "    # \"`name` == 'context'\",\n",
    "    \"`lengthscale` == 1.\",\n",
    "    \"`variance` == 1.\",\n",
    "    \"`beta1` == 15\",\n",
    "    # \"`noise` == 0.1\",\n",
    "    # \"`optim/n_steps` == 100000\",\n",
    "    # \"(`data/n_train` == 80000. | `data/num_samples_train` == 80000.)\",\n",
    "    \"`n_points` == '[25, 648]'\",\n",
    "]\n",
    "criteria = [\"all\"] if criteria == [] else criteria\n",
    "runs_df = query(runs_df, \" & \".join(criteria))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[370], line 36\u001b[0m\n\u001b[1;32m     23\u001b[0m results \u001b[39m=\u001b[39m runs_df\u001b[39m.\u001b[39mquery(\u001b[39m\"\u001b[39m\u001b[39m`dataset` == \u001b[39m\u001b[39m'\u001b[39m\u001b[39mDiv-free\u001b[39m\u001b[39m'\u001b[39m\u001b[39m & `data/n_train` >= 50\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m results \u001b[39m=\u001b[39m (\n\u001b[1;32m     26\u001b[0m         results\u001b[39m.\u001b[39mgroupby(by\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mmethod\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdata/n_train\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     27\u001b[0m         \u001b[39m.\u001b[39magg(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m     34\u001b[0m     )\n\u001b[0;32m---> 36\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, sharex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, sharey\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, figsize\u001b[39m=\u001b[39m(pw, pw \u001b[39m/\u001b[39;49m \u001b[39m4\u001b[39;49m))\n\u001b[1;32m     37\u001b[0m fig\u001b[39m.\u001b[39msubplots_adjust(wspace\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, hspace\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[39m# methods = [\"NDP (White)\", \"Tensor Field\", \"SE(3)-Transformer\"]\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "plt.rcParams[\"font.family\"] = [\"Latin Modern Roman\"]\n",
    "plt.rcParams.update({\"font.size\": 10.95})\n",
    "pw = '397.48499pt'\n",
    "lw = pw\n",
    "\n",
    "ci = 0.95\n",
    "alpha = (1 - ci) / 2\n",
    "\n",
    "def half_ci(group):\n",
    "    data = group.to_numpy()\n",
    "    sem = stats.sem(data)\n",
    "    t2 = stats.t.ppf(1 - alpha, len(data) - 1) - stats.t.ppf(alpha, len(data) - 1)\n",
    "    return sem * (t2 / 2)\n",
    "    # return np.std(data)\n",
    "\n",
    "metric = \"prior_logp\"\n",
    "metric = \"cond_logp\"\n",
    "val_metric = metric\n",
    "results = runs_df.query(\"`dataset` == 'Div-free' & `data/n_train` >= 50\")\n",
    "\n",
    "results = (\n",
    "        results.groupby(by=[\"method\", \"dataset\", \"data/n_train\"])\n",
    "        .agg(\n",
    "            {\n",
    "                metric: [\"mean\", \"std\", \"sem\", half_ci, \"count\"],\n",
    "                val_metric: [\"mean\", \"std\", \"sem\", half_ci, \"count\"],\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, sharex=True, sharey=True, figsize=(pw, pw / 4))\n",
    "fig.subplots_adjust(wspace=0, hspace=0.0)\n",
    "# methods = [\"NDP (White)\", \"Tensor Field\", \"SE(3)-Transformer\"]\n",
    "methods = [\"NDP (White)\", \"Tensor Field\"]\n",
    "for i, method in enumerate(methods):\n",
    "    idx = results[\"method\"] == method\n",
    "    x = results[idx][\"data/n_train\"]\n",
    "    y = results[idx][metric][\"mean\"]\n",
    "    # y_err = results[idx][metric][\"sem\"]\n",
    "    y_err = results[idx][metric][\"half_ci\"]\n",
    "    print(y_err)\n",
    "    ax.errorbar(x, y, y_err, color=f\"C{i}\", label=method)\n",
    "    ax.set_xscale('log')\n",
    "    # ax.set_yscale('log')\n",
    "    ax.set_ylim(0.5, .8)\n",
    "    # ax.set_ylim(-100, .8)\n",
    "fig.legend()\n",
    "fig.show()\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually adding the CNP results!\n",
    "\n",
    "columns = ['group', 'method', \"config/seed\", 'dataset', 'cond_logp']\n",
    "rows = [\n",
    "    [\"ConvCNP\", \"ConvCNP\", 1, \"Curl-free\", -1.7677894592285157],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 2, \"Curl-free\", -1.7930784861246745],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 3, \"Curl-free\", -1.7732168833414714],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 4, \"Curl-free\", -1.7641785939534504],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 5, \"Curl-free\", -1.7661763509114583],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 1, \"Div-free\", -1.7574120839436849],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 2, \"Div-free\", -1.7526724497477213],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 3, \"Div-free\", -1.7614798227945963],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 4, \"Div-free\", -1.7596895853678385],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 5, \"Div-free\", -1.7613946278889974],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 1, \"SE\", -1.7010875701904298],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 2, \"SE\", -1.7113407135009766],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 3, \"SE\", -1.7199483235677084],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 4, \"SE\", -1.7112767537434896],\n",
    "    [\"ConvCNP\", \"ConvCNP\", 5, \"SE\", -1.6989725748697917],\n",
    "    [\"C4\", \"SteerCNP\", 1, \"Curl-free\", -1.5672126770019532],\n",
    "    [\"C4\", \"SteerCNP\", 2, \"Curl-free\", -1.5728504180908203],\n",
    "    [\"C4\", \"SteerCNP\", 3, \"Curl-free\", -1.5713305155436197],\n",
    "    [\"C4\", \"SteerCNP\", 4, \"Curl-free\", -1.5724315643310547],\n",
    "    [\"C4\", \"SteerCNP\", 5, \"Curl-free\", -1.5712619781494142],\n",
    "    [\"C4\", \"SteerCNP\", 1, \"Div-free\", -1.5733726501464844],\n",
    "    [\"C4\", \"SteerCNP\", 2, \"Div-free\", -1.5614351908365884],\n",
    "    [\"C4\", \"SteerCNP\", 3, \"Div-free\", -1.574195353190104],\n",
    "    [\"C4\", \"SteerCNP\", 4, \"Div-free\", -1.5771334330240885],\n",
    "    [\"C4\", \"SteerCNP\", 1, \"SE\", -1.6106020609537761],\n",
    "    [\"C4\", \"SteerCNP\", 2, \"SE\", -1.6136614481608074],\n",
    "    [\"C4\", \"SteerCNP\", 3, \"SE\", -1.6125297546386719],\n",
    "    [\"C4\", \"SteerCNP\", 4, \"SE\", -1.6106975555419922],\n",
    "    [\"C4\", \"SteerCNP\", 5, \"SE\", -1.6165941874186198],\n",
    "    [\"GP\", \"GP\", 1, \"Curl-free\", 0.6598717212677002],\n",
    "    [\"GP\", \"GP\", 2, \"Curl-free\", 0.6598289966583252],\n",
    "    [\"GP\", \"GP\", 3, \"Curl-free\", 0.6598330497741699],\n",
    "    [\"GP\", \"GP\", 4, \"Curl-free\", 0.6598613739013672],\n",
    "    [\"GP\", \"GP\", 5, \"Curl-free\", 0.6598188877105713],\n",
    "    [\"GP\", \"GP\", 1, \"Div-free\", 0.6602359294891358],\n",
    "    [\"GP\", \"GP\", 2, \"Div-free\", 0.6602742195129394],\n",
    "    [\"GP\", \"GP\", 3, \"Div-free\", 0.6602205753326416],\n",
    "    [\"GP\", \"GP\", 4, \"Div-free\", 0.6602634906768798],\n",
    "    [\"GP\", \"GP\", 5, \"Div-free\", 0.6602737426757812],\n",
    "    [\"GP\", \"GP\", 1, \"SE\", 0.5573758125305176],\n",
    "    [\"GP\", \"GP\", 2, \"SE\", 0.5573612689971924],\n",
    "    [\"GP\", \"GP\", 3, \"SE\", 0.5573762893676758],\n",
    "    [\"GP\", \"GP\", 4, \"SE\", 0.5574379444122315],\n",
    "    [\"GP\", \"GP\", 5, \"SE\", 0.5574140071868896],\n",
    "    [\"GP\", \"GP (diag.)\", 1, \"Curl-free\", -1.4716421127319337],\n",
    "    [\"GP\", \"GP (diag.)\", 2, \"Curl-free\", -1.4714653968811036],\n",
    "    [\"GP\", \"GP (diag.)\", 3, \"Curl-free\", -1.4716914176940918],\n",
    "    [\"GP\", \"GP (diag.)\", 4, \"Curl-free\", -1.471421241760254],\n",
    "    [\"GP\", \"GP (diag.)\", 5, \"Curl-free\", -1.471923542022705],\n",
    "    [\"GP\", \"GP (diag.)\", 1, \"Div-free\", -1.466759204864502],\n",
    "    [\"GP\", \"GP (diag.)\", 2, \"Div-free\", -1.4690001487731934],\n",
    "    [\"GP\", \"GP (diag.)\", 3, \"Div-free\", -1.4697052001953126],\n",
    "    [\"GP\", \"GP (diag.)\", 4, \"Div-free\", -1.4679842948913575],\n",
    "    [\"GP\", \"GP (diag.)\", 5, \"Div-free\", -1.4686187744140624],\n",
    "    [\"GP\", \"GP (diag.)\", 1, \"SE\", -1.559639072418213],\n",
    "    [\"GP\", \"GP (diag.)\", 2, \"SE\", -1.5616438865661622],\n",
    "    [\"GP\", \"GP (diag.)\", 3, \"SE\", -1.5610824584960938],\n",
    "    [\"GP\", \"GP (diag.)\", 4, \"SE\", -1.5596550941467284],\n",
    "    [\"GP\", \"GP (diag.)\", 5, \"SE\", -1.5608834266662597],\n",
    "    ]\n",
    "cnp_runs_df = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "runs_df = pd.concat([runs_df, cnp_runs_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>method</th>\n",
       "      <th>dataset</th>\n",
       "      <th colspan=\"4\" halign=\"left\">cond_logp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>sem</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>context_data.n_points=[25,648],data.n_train=80000,data_kernel=divfree,net=mattn</td>\n",
       "      <td>NDP (White)</td>\n",
       "      <td>Div-free</td>\n",
       "      <td>0.622912</td>\n",
       "      <td>0.005073</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             group  \\\n",
       "                                                                                     \n",
       "0  context_data.n_points=[25,648],data.n_train=80000,data_kernel=divfree,net=mattn   \n",
       "\n",
       "        method   dataset cond_logp                            \n",
       "                              mean       std       sem count  \n",
       "0  NDP (White)  Div-free  0.622912  0.005073  0.002269     5  "
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = runs_df.query(\"`method` == 'NDP (White)' & `dataset` == 'Div-free'\")#[\"cond_logp\"]\n",
    "results = (\n",
    "        results.groupby(by=[\"group\", \"method\", \"dataset\"])\n",
    "        .agg(\n",
    "            {\n",
    "                metric: [\"mean\", \"std\", \"sem\", \"count\"],\n",
    "            }\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(data) 5\n",
      "stats.t.ppf(1 - alpha, len(data) - 1) 2.7764451051977987\n",
      "stats.t.ppf(alpha, len(data) - 1) -2.7764451051977987\n",
      "t2 5.5528902103955975\n",
      "sem 0.0009998398116324934\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[362], line 23\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39m# metric = \"prior_logp\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m# metric = \"true_logp\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m non_gp_idx \u001b[39m=\u001b[39m runs_df[\u001b[39m\"\u001b[39m\u001b[39mmethod\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39misin([\u001b[39m\"\u001b[39m\u001b[39mGP\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mGP (diag.)\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m test_table \u001b[39m=\u001b[39m make_table_from_metric(\n\u001b[1;32m     24\u001b[0m     metric, runs_df[\u001b[39m~\u001b[39;49mnon_gp_idx], val_metric\u001b[39m=\u001b[39;49mmetric, drop_nans\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, latex\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, bold\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, show_group\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, select_best\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m test_table[\u001b[39m\"\u001b[39m\u001b[39mmethod\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m test_table[\u001b[39m\"\u001b[39m\u001b[39mmethod\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mreplace(\n\u001b[1;32m     27\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mNDP (White)\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mNDP\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mTensor Field\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mEquiv NDP\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[39mprint\u001b[39m(test_table[[\u001b[39m\"\u001b[39m\u001b[39mgroup\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m\"\u001b[39m]])\n",
      "Cell \u001b[0;32mIn[356], line 56\u001b[0m, in \u001b[0;36mmake_table_from_metric\u001b[0;34m(metric, results, val_metric, ci, latex, bold, drop_nans, show_group, select_best, pm, uncertainty)\u001b[0m\n\u001b[1;32m     51\u001b[0m     data \u001b[39m=\u001b[39m group\u001b[39m.\u001b[39mto_numpy()\n\u001b[1;32m     52\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mprod(data\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     55\u001b[0m results \u001b[39m=\u001b[39m (\n\u001b[0;32m---> 56\u001b[0m     results\u001b[39m.\u001b[39;49mgroupby(by\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mgroup\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mmethod\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mdataset\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m     57\u001b[0m     \u001b[39m.\u001b[39;49magg(\n\u001b[1;32m     58\u001b[0m         {\n\u001b[1;32m     59\u001b[0m             metric: [\u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstd\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msem\u001b[39;49m\u001b[39m\"\u001b[39;49m, lower_ci, upper_ci, half_ci, count],\n\u001b[1;32m     60\u001b[0m             val_metric: [\n\u001b[1;32m     61\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     62\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstd\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     63\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39msem\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     64\u001b[0m                 lower_ci,\n\u001b[1;32m     65\u001b[0m                 upper_ci,\n\u001b[1;32m     66\u001b[0m                 half_ci,\n\u001b[1;32m     67\u001b[0m                 count,\n\u001b[1;32m     68\u001b[0m             ],\n\u001b[1;32m     69\u001b[0m         }\n\u001b[1;32m     70\u001b[0m     )\n\u001b[1;32m     71\u001b[0m     \u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m     72\u001b[0m )\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m select_best:\n\u001b[1;32m     75\u001b[0m     group_max_idx \u001b[39m=\u001b[39m (\n\u001b[1;32m     76\u001b[0m         results\u001b[39m.\u001b[39mgroupby(by\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mmethod\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39mtransform(\u001b[39mmax\u001b[39m)[val_metric][\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     77\u001b[0m         \u001b[39m==\u001b[39m results[val_metric][\u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     78\u001b[0m     )\n",
      "File \u001b[0;32m/scratch/ebm32/miniconda3/envs/venv/lib/python3.9/site-packages/pandas/core/groupby/generic.py:895\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    892\u001b[0m func \u001b[39m=\u001b[39m maybe_mangle_lambdas(func)\n\u001b[1;32m    894\u001b[0m op \u001b[39m=\u001b[39m GroupByApply(\u001b[39mself\u001b[39m, func, args, kwargs)\n\u001b[0;32m--> 895\u001b[0m result \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39;49magg()\n\u001b[1;32m    896\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dict_like(func) \u001b[39mand\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    897\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/scratch/ebm32/miniconda3/envs/venv/lib/python3.9/site-packages/pandas/core/apply.py:172\u001b[0m, in \u001b[0;36mApply.agg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m is_dict_like(arg):\n\u001b[0;32m--> 172\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magg_dict_like()\n\u001b[1;32m    173\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(arg):\n\u001b[1;32m    174\u001b[0m     \u001b[39m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magg_list_like()\n",
      "File \u001b[0;32m/scratch/ebm32/miniconda3/envs/venv/lib/python3.9/site-packages/pandas/core/apply.py:504\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    501\u001b[0m     results \u001b[39m=\u001b[39m {key: colg\u001b[39m.\u001b[39magg(how) \u001b[39mfor\u001b[39;00m key, how \u001b[39min\u001b[39;00m arg\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    502\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    503\u001b[0m     \u001b[39m# key used for column selection and output\u001b[39;00m\n\u001b[0;32m--> 504\u001b[0m     results \u001b[39m=\u001b[39m {\n\u001b[1;32m    505\u001b[0m         key: obj\u001b[39m.\u001b[39m_gotitem(key, ndim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39magg(how) \u001b[39mfor\u001b[39;00m key, how \u001b[39min\u001b[39;00m arg\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    506\u001b[0m     }\n\u001b[1;32m    508\u001b[0m \u001b[39m# set the final keys\u001b[39;00m\n\u001b[1;32m    509\u001b[0m keys \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(arg\u001b[39m.\u001b[39mkeys())\n",
      "File \u001b[0;32m/scratch/ebm32/miniconda3/envs/venv/lib/python3.9/site-packages/pandas/core/apply.py:505\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    501\u001b[0m     results \u001b[39m=\u001b[39m {key: colg\u001b[39m.\u001b[39magg(how) \u001b[39mfor\u001b[39;00m key, how \u001b[39min\u001b[39;00m arg\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m    502\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    503\u001b[0m     \u001b[39m# key used for column selection and output\u001b[39;00m\n\u001b[1;32m    504\u001b[0m     results \u001b[39m=\u001b[39m {\n\u001b[0;32m--> 505\u001b[0m         key: obj\u001b[39m.\u001b[39;49m_gotitem(key, ndim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49magg(how) \u001b[39mfor\u001b[39;00m key, how \u001b[39min\u001b[39;00m arg\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    506\u001b[0m     }\n\u001b[1;32m    508\u001b[0m \u001b[39m# set the final keys\u001b[39;00m\n\u001b[1;32m    509\u001b[0m keys \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(arg\u001b[39m.\u001b[39mkeys())\n",
      "File \u001b[0;32m/scratch/ebm32/miniconda3/envs/venv/lib/python3.9/site-packages/pandas/core/groupby/generic.py:281\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(func, abc\u001b[39m.\u001b[39mIterable):\n\u001b[1;32m    278\u001b[0m     \u001b[39m# Catch instances of lists / tuples\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     \u001b[39m# but not the class list / tuple itself.\u001b[39;00m\n\u001b[1;32m    280\u001b[0m     func \u001b[39m=\u001b[39m maybe_mangle_lambdas(func)\n\u001b[0;32m--> 281\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_aggregate_multiple_funcs(func)\n\u001b[1;32m    282\u001b[0m     \u001b[39mif\u001b[39;00m relabeling:\n\u001b[1;32m    283\u001b[0m         \u001b[39m# columns is not narrowed by mypy from relabeling flag\u001b[39;00m\n\u001b[1;32m    284\u001b[0m         \u001b[39massert\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m  \u001b[39m# for mypy\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/ebm32/miniconda3/envs/venv/lib/python3.9/site-packages/pandas/core/groupby/generic.py:336\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_multiple_funcs\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39mfor\u001b[39;00m idx, (name, func) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(arg):\n\u001b[1;32m    335\u001b[0m     key \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mOutputKey(label\u001b[39m=\u001b[39mname, position\u001b[39m=\u001b[39midx)\n\u001b[0;32m--> 336\u001b[0m     results[key] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggregate(func)\n\u001b[1;32m    338\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, DataFrame) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m results\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    339\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mimport\u001b[39;00m concat\n",
      "File \u001b[0;32m/scratch/ebm32/miniconda3/envs/venv/lib/python3.9/site-packages/pandas/core/groupby/generic.py:294\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, cyfunc)()\n\u001b[1;32m    293\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrouper\u001b[39m.\u001b[39mnkeys \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 294\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_agg_general(func, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    296\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_python_agg_general(func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/scratch/ebm32/miniconda3/envs/venv/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1682\u001b[0m, in \u001b[0;36mGroupBy._python_agg_general\u001b[0;34m(self, func, raise_on_typeerror, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1678\u001b[0m name \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mname\n\u001b[1;32m   1680\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1681\u001b[0m     \u001b[39m# if this function is invalid for this dtype, we will ignore it.\u001b[39;00m\n\u001b[0;32m-> 1682\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgrouper\u001b[39m.\u001b[39;49magg_series(obj, f)\n\u001b[1;32m   1683\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   1684\u001b[0m     \u001b[39mif\u001b[39;00m raise_on_typeerror:\n",
      "File \u001b[0;32m/scratch/ebm32/miniconda3/envs/venv/lib/python3.9/site-packages/pandas/core/groupby/ops.py:1081\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m   1078\u001b[0m     preserve_dtype \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1081\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_aggregate_series_pure_python(obj, func)\n\u001b[1;32m   1083\u001b[0m npvalues \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   1084\u001b[0m \u001b[39mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[0;32m/scratch/ebm32/miniconda3/envs/venv/lib/python3.9/site-packages/pandas/core/groupby/ops.py:1104\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m   1101\u001b[0m splitter \u001b[39m=\u001b[39m get_splitter(obj, ids, ngroups, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m   1103\u001b[0m \u001b[39mfor\u001b[39;00m i, group \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(splitter):\n\u001b[0;32m-> 1104\u001b[0m     res \u001b[39m=\u001b[39m func(group)\n\u001b[1;32m   1105\u001b[0m     res \u001b[39m=\u001b[39m libreduction\u001b[39m.\u001b[39mextract_result(res)\n\u001b[1;32m   1107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m initialized:\n\u001b[1;32m   1108\u001b[0m         \u001b[39m# We only do this validation on the first iteration\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/ebm32/miniconda3/envs/venv/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:1668\u001b[0m, in \u001b[0;36mGroupBy._python_agg_general.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1665\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   1666\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_python_agg_general\u001b[39m(\u001b[39mself\u001b[39m, func, \u001b[39m*\u001b[39margs, raise_on_typeerror\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1667\u001b[0m     func \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mis_builtin_func(func)\n\u001b[0;32m-> 1668\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: func(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1670\u001b[0m     \u001b[39m# iterate through \"columns\" ex exclusions to populate output dict\u001b[39;00m\n\u001b[1;32m   1671\u001b[0m     output: \u001b[39mdict\u001b[39m[base\u001b[39m.\u001b[39mOutputKey, ArrayLike] \u001b[39m=\u001b[39m {}\n",
      "Cell \u001b[0;32mIn[356], line 32\u001b[0m, in \u001b[0;36mmake_table_from_metric.<locals>.half_ci\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mt2\u001b[39m\u001b[39m\"\u001b[39m, t2)\n\u001b[1;32m     31\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39msem\u001b[39m\u001b[39m\"\u001b[39m, sem)\n\u001b[0;32m---> 32\u001b[0m \u001b[39mraise\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39mreturn\u001b[39;00m sem \u001b[39m*\u001b[39m (t2 \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "def format(table, row_names=[]):\n",
    "    cols = [\"method\", \"dataset\", \"result\"]\n",
    "    table = table[cols].pivot(index=\"method\", columns=\"dataset\")\n",
    "    if len(row_names) > 0:\n",
    "        table = table.reindex(row_names)\n",
    "    table.index = [f\"\\\\scshape {x}\" for x in table.index]\n",
    "\n",
    "    table = table.droplevel(level=0, axis=1)\n",
    "    table = table.droplevel(level=0, axis=1)\n",
    "    table = table[[\"SE\", \"Curl-free\", \"Div-free\"]]\n",
    "    table.columns = [f\"\\\\scshape {x}\" for x in table.columns]\n",
    "    table.columns.name = \"\\\\textsc{Model}\"\n",
    "    table.index.name = None\n",
    "    return table\n",
    "\n",
    "metric = \"cond_logp\"\n",
    "# metric = \"prior_logp\"\n",
    "# metric = \"true_logp\"\n",
    "\n",
    "\n",
    "non_gp_idx = runs_df[\"method\"].isin([\"GP\", \"GP (diag.)\"])\n",
    "\n",
    "test_table = make_table_from_metric(\n",
    "    metric, runs_df[~non_gp_idx], val_metric=metric, drop_nans=False, latex=True, bold=True, show_group=False, select_best=True\n",
    ")\n",
    "test_table[\"method\"] = test_table[\"method\"].replace(\n",
    "    {\"NDP (White)\": \"NDP\",\n",
    "    \"Tensor Field\": \"Equiv NDP\"},\n",
    ")\n",
    "\n",
    "print(test_table[[\"group\", \"result\"]])\n",
    "row_names=[\"ConvCNP\", \"SteerCNP\", \"NDP\", \"SE(3)-Transformer\", \"Equiv NDP\"]\n",
    "table = format(test_table, row_names=row_names)\n",
    "print(table)\n",
    "gp_test_table = make_table_from_metric(\n",
    "    metric, runs_df[non_gp_idx], val_metric=metric, drop_nans=False, latex=True, bold=False, show_group=False, select_best=True, pm=True, uncertainty='sem'\n",
    ")\n",
    "# # print(gp_test_table)\n",
    "gp_table = format(gp_test_table, row_names=[\"GP (diag.)\", \"GP\"])\n",
    "table = pd.concat([table, gp_table])\n",
    "# row_names = [\"ConvCNP\", \"SteerCNP\", \"GP (diag.)\", \"NDP (White)\", \"SE(3)-Transformer\", \"Tensor Field\", \"GP\"]\n",
    "row_names = [\"ConvCNP\", \"SteerCNP\", \"GP (diag.)\", \"NDP\", \"Equiv NDP\", \"SE(3)-Transformer\", \"GP\"]\n",
    "table = table.reindex([f\"\\\\scshape {row}\" for row in row_names])\n",
    "\n",
    "import os\n",
    "latex_path = \"table.tex\"\n",
    "filename = os.path.join(os.getcwd(), latex_path)\n",
    "print(filename)\n",
    "table.style.to_latex(\n",
    "    buf=filename, hrules=True, multicol_align=\"c\", column_format=\"lrrr\"\n",
    ")\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
