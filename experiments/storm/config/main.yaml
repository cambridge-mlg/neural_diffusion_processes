# @package _global_

defaults:
  # GENERAL #
  - _self_

  - server: base
  - logger: csv

  - net: mattn
  - lr_schedule: rcosine
  - beta_schedule: linear
  - kernel: whitevec

  
  # enable color logging
  - override hydra/hydra_logging: default
  - override hydra/job_logging: default


# net:
#   n_layers: 5
#   hidden_dim: 64

name: storm_data
mode: train
seed: 0

beta_schedule:
  # t0: 3e-4
  t0: 5e-4
  t1: 1.0
  beta0: 1e-4
  beta1: 15.0

optim:
  # batch_size: 30
  batch_size: 20
  eval_batch_size: ${eval:${optim.batch_size}//8}
  num_steps: 50_000
  lr: 1e-3
  ema_rate: 0.999

data:
  _target_: neural_diffusion_processes.data.storm_data
  max_len: 50
  seed_test: 1
  num_samples_test:  64
  # num_samples_test: 20_000
  seed: 0
  # min_context: 5
  # max_context: 50
  min_context: 30
  max_context: ${data.min_context}
  # n_points: 50
  n_points: -1

kernel:
  params:
    variance: ${data.variance}
    lengthscale: 2.

sde:
  _target_: neural_diffusion_processes.sde.SDE
  std_trick: true
  residual_trick: true
  # limiting_kernel_hyperparameters: 
  #   variance: 1.0
  #   lengthscale: 1.0
  limiting_kernel: ${kernel.cls}
    # _target_: neural_diffusion_processes.kernels.RBFVec
    # _target_: neural_diffusion_processes.kernels.WhiteVec
    # output_dim: 2
  limiting_mean_fn:
    _target_: gpjax.Zero
    output_dim: 2

net:
  n_layers: 5
  hidden_dim: 64
  num_heads: 4

# eval_batch_size: ${batch_size}
now: ${now:%Y-%m-%d}/${now:%H-%M-%S}

# resume: false
# mode: all
PROJECT_NAME: score-sde
# PROJECT_NAME: neural_diffusion_processes